tpt maxlogit txt
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='VisdaOOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='tpt', workers=4)


10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.

Step 999: Top1: 0.8498; Top5: 0.9918
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8497942386831275, 'ACC_ID': 0.6604938271604939, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 1999: Top1: 0.8556; Top5: 0.9920
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8555667001003009, 'ACC_ID': 0.6670010030090271, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 2999: Top1: 0.8476; Top5: 0.9920
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8476953907815631, 'ACC_ID': 0.6606546426185704, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 3999: Top1: 0.8487; Top5: 0.9890
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8488023952095808, 'ACC_ID': 0.6641716566866267, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 4999: Top1: 0.8502; Top5: 0.9872
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8499001996007984, 'ACC_ID': 0.6630738522954092, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 5999: Top1: 0.8479; Top5: 0.9867
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8476095617529881, 'ACC_ID': 0.6600265604249668, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 6999: Top1: 0.8491; Top5: 0.9875
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8488471391972673, 'ACC_ID': 0.6655280387133504, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 7999: Top1: 0.8464; Top5: 0.9868
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.845962113659023, 'ACC_ID': 0.6625124626121635, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 8999: Top1: 0.8455; Top5: 0.9869
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8448697974627198, 'ACC_ID': 0.6605831293122635, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 9999: Top1: 0.8460; Top5: 0.9868
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8454600120264583, 'ACC_ID': 0.6622569653237121, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 10999: Top1: 0.8471; Top5: 0.9866
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8462654097171863, 'ACC_ID': 0.6660623640319072, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 11999: Top1: 0.8485; Top5: 0.9864
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8477359429424448, 'ACC_ID': 0.6661137833803285, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 12999: Top1: 0.8490; Top5: 0.9868
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8482705611068408, 'ACC_ID': 0.6654880860876249, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 13999: Top1: 0.8474; Top5: 0.9869
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8467236467236468, 'ACC_ID': 0.6625356125356126, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 14999: Top1: 0.8476; Top5: 0.9871
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8469807564698075, 'ACC_ID': 0.6630391506303915, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 15999: Top1: 0.8478; Top5: 0.9870
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8471615720524017, 'ACC_ID': 0.6622582657517155, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 16999: Top1: 0.8474; Top5: 0.9873
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8467865115732581, 'ACC_ID': 0.6630243214663377, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 17999: Top1: 0.8471; Top5: 0.9874
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.846520390070922, 'ACC_ID': 0.6627881205673759, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 18999: Top1: 0.8481; Top5: 0.9871
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8475289169295478, 'ACC_ID': 0.6635120925341745, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 19999: Top1: 0.8478; Top5: 0.9865
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8473, 'ACC_ID': 0.6647, 'ACC_OOD': 0, 'ACC_HM': 0}



VisdaOOD MNIST tpt_txt maxlogit
Final metrics: Top-1 accuracy: 84.7800; Top-5 accuracy: 98.6500
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0.9355348050000001, 'FPR95': 0.5339, 'ACC_ALL': 0.8473, 'ACC_ID': 0.6647, 'ACC_OOD': 0.9939, 'ACC_HM': 0.7966300856143735}




Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='VisdaOOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='tpt', workers=4)


Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/train_32x32.mat
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.

Step 999: Top1: 0.8519; Top5: 0.9918
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8518518518518519, 'ACC_ID': 0.6625514403292181, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 1999: Top1: 0.8566; Top5: 0.9920
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8565697091273822, 'ACC_ID': 0.6680040120361084, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 2999: Top1: 0.8483; Top5: 0.9920
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8483633934535738, 'ACC_ID': 0.6613226452905812, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 3999: Top1: 0.8492; Top5: 0.9890
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8493013972055888, 'ACC_ID': 0.6646706586826348, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 4999: Top1: 0.8506; Top5: 0.9872
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8502994011976048, 'ACC_ID': 0.6634730538922156, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 5999: Top1: 0.8479; Top5: 0.9867
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8476095617529881, 'ACC_ID': 0.6600265604249668, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 6999: Top1: 0.8491; Top5: 0.9872
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8488471391972673, 'ACC_ID': 0.6655280387133504, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 7999: Top1: 0.8464; Top5: 0.9865
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.845962113659023, 'ACC_ID': 0.6625124626121635, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 8999: Top1: 0.8455; Top5: 0.9866
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8448697974627198, 'ACC_ID': 0.6605831293122635, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 9999: Top1: 0.8460; Top5: 0.9866
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8454600120264583, 'ACC_ID': 0.6622569653237121, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 10999: Top1: 0.8471; Top5: 0.9864
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8462654097171863, 'ACC_ID': 0.666243654822335, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 11999: Top1: 0.8485; Top5: 0.9862
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8477359429424448, 'ACC_ID': 0.6662796483662299, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 12999: Top1: 0.8490; Top5: 0.9866
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8482705611068408, 'ACC_ID': 0.665641813989239, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 13999: Top1: 0.8474; Top5: 0.9868
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8467236467236468, 'ACC_ID': 0.6626780626780627, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 14999: Top1: 0.8476; Top5: 0.9870
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8469807564698075, 'ACC_ID': 0.6631718646317186, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 15999: Top1: 0.8478; Top5: 0.9869
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8471615720524017, 'ACC_ID': 0.6623830318153462, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 16999: Top1: 0.8474; Top5: 0.9872
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8467865115732581, 'ACC_ID': 0.6631418164727999, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 17999: Top1: 0.8471; Top5: 0.9873
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.846520390070922, 'ACC_ID': 0.6628989361702128, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 18999: Top1: 0.8481; Top5: 0.9870
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8475289169295478, 'ACC_ID': 0.6636172450052576, 'ACC_OOD': 0, 'ACC_HM': 0}

Step 19999: Top1: 0.8478; Top5: 0.9864
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8473, 'ACC_ID': 0.6648, 'ACC_OOD': 0, 'ACC_HM': 0}



VisdaOOD SVHN tpt_txt maxlogit
Final metrics: Top-1 accuracy: 84.7800; Top-5 accuracy: 98.6400
{'Method': 'tpt_txt', 'OOD Detector': 'maxlogit', 'AUC': 0.94420579, 'FPR95': 0.385, 'ACC_ALL': 0.8473, 'ACC_ID': 0.6648, 'ACC_OOD': 0.9896, 'ACC_HM': 0.7953168278529981}




Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='ImagenetROOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='tpt', workers=4)


len 10000
dict_values(['goldfish', 'great white shark', 'hammerhead shark', 'stingray', 'hen', 'ostrich', 'goldfinch', 'junco', 'bald eagle', 'vulture', 'smooth newt', 'axolotl', 'tree frog', 'green iguana', 'chameleon', 'Indian cobra', 'scorpion', 'tarantula', 'centipede', 'peafowl', 'lorikeet', 'hummingbird', 'toucan', 'duck', 'goose', 'black swan', 'koala', 'jellyfish', 'snail', 'American lobster', 'hermit crab', 'flamingo', 'great egret', 'pelican', 'king penguin', 'grey whale', 'killer whale', 'sea lion', 'Chihuahua', 'Shih Tzu', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Italian Greyhound', 'Whippet', 'Weimaraner', 'Yorkshire Terrier', 'Boston Terrier', 'Scottish Terrier', 'West Highland White Terrier', 'Golden Retriever', 'Labrador Retriever', 'Cocker Spaniel', 'collie', 'Border Collie', 'Rottweiler', 'German Shepherd Dog', 'Boxer', 'French Bulldog', 'St. Bernard', 'Siberian Husky', 'Dalmatian', 'pug', 'Pomeranian', 'Chow Chow', 'Pembroke Welsh Corgi', 'Toy Poodle', 'Standard Poodle', 'grey wolf', 'hyena', 'red fox', 'tabby cat', 'leopard', 'snow leopard', 'lion', 'tiger', 'cheetah', 'polar bear', 'meerkat', 'ladybug', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'praying mantis', 'dragonfly', 'monarch butterfly', 'starfish', 'cottontail rabbit', 'porcupine', 'fox squirrel', 'beaver', 'guinea pig', 'zebra', 'pig', 'hippopotamus', 'bison', 'gazelle', 'llama', 'skunk', 'badger', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'baboon', 'giant panda', 'eel', 'clownfish', 'pufferfish', 'accordion', 'ambulance', 'assault rifle', 'backpack', 'barn', 'wheelbarrow', 'basketball', 'bathtub', 'lighthouse', 'beer glass', 'binoculars', 'birdhouse', 'bow tie', 'broom', 'bucket', 'cauldron', 'candle', 'cannon', 'canoe', 'carousel', 'castle', 'mobile phone', 'cowboy hat', 'electric guitar', 'fire truck', 'flute', 'gas mask or respirator', 'grand piano', 'guillotine', 'hammer', 'harmonica', 'harp', 'hatchet', 'jeep', 'joystick', 'lab coat', 'lawn mower', 'lipstick', 'mailbox', 'missile', 'mitten', 'parachute', 'pickup truck', 'pirate ship', 'revolver', 'rugby ball', 'sandal', 'saxophone', 'school bus', 'schooner', 'shield', 'soccer ball', 'space shuttle', 'spider web', 'steam locomotive', 'scarf', 'submarine', 'tank', 'tennis ball', 'tractor', 'trombone', 'vase', 'violin', 'military aircraft', 'wine bottle', 'ice cream', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'cabbage', 'broccoli', 'cucumber', 'bell pepper', 'mushroom', 'Granny Smith apple', 'strawberry', 'lemon', 'pineapple', 'banana', 'pomegranate', 'pizza', 'burrito', 'espresso', 'volcano', 'baseball player', 'scuba diver', 'acorn'])
len 10000
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='ImagenetROOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='tpt', workers=4)


len 10000
dict_values(['goldfish', 'great white shark', 'hammerhead shark', 'stingray', 'hen', 'ostrich', 'goldfinch', 'junco', 'bald eagle', 'vulture', 'smooth newt', 'axolotl', 'tree frog', 'green iguana', 'chameleon', 'Indian cobra', 'scorpion', 'tarantula', 'centipede', 'peafowl', 'lorikeet', 'hummingbird', 'toucan', 'duck', 'goose', 'black swan', 'koala', 'jellyfish', 'snail', 'American lobster', 'hermit crab', 'flamingo', 'great egret', 'pelican', 'king penguin', 'grey whale', 'killer whale', 'sea lion', 'Chihuahua', 'Shih Tzu', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Italian Greyhound', 'Whippet', 'Weimaraner', 'Yorkshire Terrier', 'Boston Terrier', 'Scottish Terrier', 'West Highland White Terrier', 'Golden Retriever', 'Labrador Retriever', 'Cocker Spaniel', 'collie', 'Border Collie', 'Rottweiler', 'German Shepherd Dog', 'Boxer', 'French Bulldog', 'St. Bernard', 'Siberian Husky', 'Dalmatian', 'pug', 'Pomeranian', 'Chow Chow', 'Pembroke Welsh Corgi', 'Toy Poodle', 'Standard Poodle', 'grey wolf', 'hyena', 'red fox', 'tabby cat', 'leopard', 'snow leopard', 'lion', 'tiger', 'cheetah', 'polar bear', 'meerkat', 'ladybug', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'praying mantis', 'dragonfly', 'monarch butterfly', 'starfish', 'cottontail rabbit', 'porcupine', 'fox squirrel', 'beaver', 'guinea pig', 'zebra', 'pig', 'hippopotamus', 'bison', 'gazelle', 'llama', 'skunk', 'badger', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'baboon', 'giant panda', 'eel', 'clownfish', 'pufferfish', 'accordion', 'ambulance', 'assault rifle', 'backpack', 'barn', 'wheelbarrow', 'basketball', 'bathtub', 'lighthouse', 'beer glass', 'binoculars', 'birdhouse', 'bow tie', 'broom', 'bucket', 'cauldron', 'candle', 'cannon', 'canoe', 'carousel', 'castle', 'mobile phone', 'cowboy hat', 'electric guitar', 'fire truck', 'flute', 'gas mask or respirator', 'grand piano', 'guillotine', 'hammer', 'harmonica', 'harp', 'hatchet', 'jeep', 'joystick', 'lab coat', 'lawn mower', 'lipstick', 'mailbox', 'missile', 'mitten', 'parachute', 'pickup truck', 'pirate ship', 'revolver', 'rugby ball', 'sandal', 'saxophone', 'school bus', 'schooner', 'shield', 'soccer ball', 'space shuttle', 'spider web', 'steam locomotive', 'scarf', 'submarine', 'tank', 'tennis ball', 'tractor', 'trombone', 'vase', 'violin', 'military aircraft', 'wine bottle', 'ice cream', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'cabbage', 'broccoli', 'cucumber', 'bell pepper', 'mushroom', 'Granny Smith apple', 'strawberry', 'lemon', 'pineapple', 'banana', 'pomegranate', 'pizza', 'burrito', 'espresso', 'volcano', 'baseball player', 'scuba diver', 'acorn'])
len 10000
Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/train_32x32.mat
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar10OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar10OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/test_32x32.mat
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar10OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='cifar100', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
Files already downloaded and verified
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar10OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='Tiny', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
len 10000
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar100OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar100OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/test_32x32.mat
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar100OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='cifar10', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
Files already downloaded and verified
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Namespace(N_m=512, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='cifar100OOD', level=5, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.7, seed=0, strong_OOD='Tiny', strong_ratio=1, tta_method='tpt', workers=4)


Test on snow level 5
Files already downloaded and verified
len 10000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2
Re-updating prompt initializations to current prompts.
Traceback (most recent call last):
  File "tta_ood_maple.py", line 191, in <module>
    result_metrics = tta_methods[args.tta_method](args, model, test_loader, ID_classifiers)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 134, in tta_id_ood
    model = tpt_test_time_tuning(model, images, optimizer, scaler)
  File "/home/manogna/TTA/clip-owtta/methods/tpt.py", line 36, in tpt_test_time_tuning
    scaler.scale(loss).backward()
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/_tensor.py", line 255, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/manogna/anaconda3/envs/promptalign/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
