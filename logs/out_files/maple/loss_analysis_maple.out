0 0
Namespace(N_m=512, alpha=0.5, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='VisdaOOD', k_n=10, k_p=3, level=5, loss_pl=0, loss_simclr=0, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.6, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='rosita_loss', workers=4)


10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2

Step 999: Top1: 0.8580; Top5: 0.9918
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8580246913580247, 'ACC_ID': 0.668724279835391, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 1999: Top1: 0.8596; Top5: 0.9920
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8595787362086259, 'ACC_ID': 0.6710130391173521, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 2999: Top1: 0.8543; Top5: 0.9926
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.85437541750167, 'ACC_ID': 0.6673346693386774, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 3999: Top1: 0.8552; Top5: 0.9895
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8552894211576846, 'ACC_ID': 0.6706586826347305, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 4999: Top1: 0.8578; Top5: 0.9880
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8578842315369262, 'ACC_ID': 0.6710578842315369, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 5999: Top1: 0.8565; Top5: 0.9877
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8565737051792829, 'ACC_ID': 0.6689907038512616, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 6999: Top1: 0.8568; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8568175348704811, 'ACC_ID': 0.6734984343865642, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 7999: Top1: 0.8549; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8546859421734796, 'ACC_ID': 0.6712362911266201, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 8999: Top1: 0.8542; Top5: 0.9889
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8539951034943245, 'ACC_ID': 0.6697084353438683, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 9999: Top1: 0.8549; Top5: 0.9888
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8546802966526358, 'ACC_ID': 0.6714772499498898, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 10999: Top1: 0.8549; Top5: 0.9884
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8544234952864395, 'ACC_ID': 0.6742204496011602, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 11999: Top1: 0.8567; Top5: 0.9881
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8561950572234202, 'ACC_ID': 0.6745728976613037, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 12999: Top1: 0.8566; Top5: 0.9885
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8561106840891621, 'ACC_ID': 0.6733282090699462, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 13999: Top1: 0.8560; Top5: 0.9885
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8555555555555555, 'ACC_ID': 0.6713675213675213, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 14999: Top1: 0.8557; Top5: 0.9887
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8553417385534173, 'ACC_ID': 0.6714001327140013, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 15999: Top1: 0.8556; Top5: 0.9886
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8552713661883967, 'ACC_ID': 0.6703680598877105, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 16999: Top1: 0.8554; Top5: 0.9890
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8550111620256139, 'ACC_ID': 0.6712489719186935, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 17999: Top1: 0.8555; Top5: 0.9889
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8551640070921985, 'ACC_ID': 0.6714317375886525, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 18999: Top1: 0.8559; Top5: 0.9887
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8556256572029443, 'ACC_ID': 0.671608832807571, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 19999: Top1: 0.8560; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8557, 'ACC_ID': 0.6731, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}
[       inf 0.35919225 0.31050348 ... 0.22230585 0.22221613 0.18473142]
VisdaOOD MNIST rosita_loss_txt maxlogit


Final metrics: Top-1 accuracy: 85.6000; Top-5 accuracy: 98.8300
{'Method': 'rosita_loss_txt', 'AUC': 0.9355348050000001, 'FPR95': 0.5339, 'ACC_ALL': 0.8557, 'ACC_ID': 0.6731, 'ACC_OOD': 0.9939, 'ACC_HM': 0.8026323815236952, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}




Namespace(N_m=512, alpha=0.5, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='VisdaOOD', k_n=10, k_p=3, level=5, loss_pl=0, loss_simclr=0, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.6, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='rosita_loss', workers=4)


Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/train_32x32.mat
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2

Step 999: Top1: 0.8580; Top5: 0.9918
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8580246913580247, 'ACC_ID': 0.668724279835391, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 1999: Top1: 0.8596; Top5: 0.9920
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8595787362086259, 'ACC_ID': 0.6710130391173521, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 2999: Top1: 0.8543; Top5: 0.9926
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.85437541750167, 'ACC_ID': 0.6673346693386774, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 3999: Top1: 0.8552; Top5: 0.9895
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8552894211576846, 'ACC_ID': 0.6706586826347305, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 4999: Top1: 0.8578; Top5: 0.9880
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8578842315369262, 'ACC_ID': 0.6710578842315369, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 5999: Top1: 0.8565; Top5: 0.9877
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8565737051792829, 'ACC_ID': 0.6689907038512616, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 6999: Top1: 0.8568; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8568175348704811, 'ACC_ID': 0.6734984343865642, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 7999: Top1: 0.8549; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8546859421734796, 'ACC_ID': 0.6712362911266201, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 8999: Top1: 0.8542; Top5: 0.9889
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8539951034943245, 'ACC_ID': 0.6697084353438683, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 9999: Top1: 0.8549; Top5: 0.9888
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8546802966526358, 'ACC_ID': 0.6714772499498898, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 10999: Top1: 0.8549; Top5: 0.9884
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8544234952864395, 'ACC_ID': 0.6744017403915881, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 11999: Top1: 0.8567; Top5: 0.9881
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8561950572234202, 'ACC_ID': 0.6747387626472052, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 12999: Top1: 0.8566; Top5: 0.9885
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8561106840891621, 'ACC_ID': 0.6734819369715603, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 13999: Top1: 0.8560; Top5: 0.9885
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8555555555555555, 'ACC_ID': 0.6715099715099715, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 14999: Top1: 0.8557; Top5: 0.9887
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8553417385534173, 'ACC_ID': 0.6715328467153284, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 15999: Top1: 0.8556; Top5: 0.9886
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8552713661883967, 'ACC_ID': 0.6704928259513412, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 16999: Top1: 0.8554; Top5: 0.9890
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8550111620256139, 'ACC_ID': 0.6713664669251557, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 17999: Top1: 0.8555; Top5: 0.9889
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8551640070921985, 'ACC_ID': 0.6715425531914894, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 18999: Top1: 0.8559; Top5: 0.9887
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8556256572029443, 'ACC_ID': 0.671713985278654, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 19999: Top1: 0.8560; Top5: 0.9883
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.8557, 'ACC_ID': 0.6732, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}
[       inf 0.35919225 0.31050348 ... 0.20758392 0.20699319 0.18473142]
VisdaOOD SVHN rosita_loss_txt maxlogit


Final metrics: Top-1 accuracy: 85.6000; Top-5 accuracy: 98.8300
{'Method': 'rosita_loss_txt', 'AUC': 0.94420579, 'FPR95': 0.385, 'ACC_ALL': 0.8557, 'ACC_ID': 0.6732, 'ACC_OOD': 0.9896, 'ACC_HM': 0.8012974741400049, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}




Namespace(N_m=512, alpha=0.5, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='ImagenetROOD', k_n=10, k_p=3, level=5, loss_pl=0, loss_simclr=0, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.6, seed=0, strong_OOD='MNIST', strong_ratio=1, tta_method='rosita_loss', workers=4)


len 10000
dict_values(['goldfish', 'great white shark', 'hammerhead shark', 'stingray', 'hen', 'ostrich', 'goldfinch', 'junco', 'bald eagle', 'vulture', 'smooth newt', 'axolotl', 'tree frog', 'green iguana', 'chameleon', 'Indian cobra', 'scorpion', 'tarantula', 'centipede', 'peafowl', 'lorikeet', 'hummingbird', 'toucan', 'duck', 'goose', 'black swan', 'koala', 'jellyfish', 'snail', 'American lobster', 'hermit crab', 'flamingo', 'great egret', 'pelican', 'king penguin', 'grey whale', 'killer whale', 'sea lion', 'Chihuahua', 'Shih Tzu', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Italian Greyhound', 'Whippet', 'Weimaraner', 'Yorkshire Terrier', 'Boston Terrier', 'Scottish Terrier', 'West Highland White Terrier', 'Golden Retriever', 'Labrador Retriever', 'Cocker Spaniel', 'collie', 'Border Collie', 'Rottweiler', 'German Shepherd Dog', 'Boxer', 'French Bulldog', 'St. Bernard', 'Siberian Husky', 'Dalmatian', 'pug', 'Pomeranian', 'Chow Chow', 'Pembroke Welsh Corgi', 'Toy Poodle', 'Standard Poodle', 'grey wolf', 'hyena', 'red fox', 'tabby cat', 'leopard', 'snow leopard', 'lion', 'tiger', 'cheetah', 'polar bear', 'meerkat', 'ladybug', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'praying mantis', 'dragonfly', 'monarch butterfly', 'starfish', 'cottontail rabbit', 'porcupine', 'fox squirrel', 'beaver', 'guinea pig', 'zebra', 'pig', 'hippopotamus', 'bison', 'gazelle', 'llama', 'skunk', 'badger', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'baboon', 'giant panda', 'eel', 'clownfish', 'pufferfish', 'accordion', 'ambulance', 'assault rifle', 'backpack', 'barn', 'wheelbarrow', 'basketball', 'bathtub', 'lighthouse', 'beer glass', 'binoculars', 'birdhouse', 'bow tie', 'broom', 'bucket', 'cauldron', 'candle', 'cannon', 'canoe', 'carousel', 'castle', 'mobile phone', 'cowboy hat', 'electric guitar', 'fire truck', 'flute', 'gas mask or respirator', 'grand piano', 'guillotine', 'hammer', 'harmonica', 'harp', 'hatchet', 'jeep', 'joystick', 'lab coat', 'lawn mower', 'lipstick', 'mailbox', 'missile', 'mitten', 'parachute', 'pickup truck', 'pirate ship', 'revolver', 'rugby ball', 'sandal', 'saxophone', 'school bus', 'schooner', 'shield', 'soccer ball', 'space shuttle', 'spider web', 'steam locomotive', 'scarf', 'submarine', 'tank', 'tennis ball', 'tractor', 'trombone', 'vase', 'violin', 'military aircraft', 'wine bottle', 'ice cream', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'cabbage', 'broccoli', 'cucumber', 'bell pepper', 'mushroom', 'Granny Smith apple', 'strawberry', 'lemon', 'pineapple', 'banana', 'pomegranate', 'pizza', 'burrito', 'espresso', 'volcano', 'baseball player', 'scuba diver', 'acorn'])
len 10000
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2

Step 999: Top1: 0.7675; Top5: 0.9115
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7674897119341564, 'ACC_ID': 0.6213991769547325, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 1999: Top1: 0.7663; Top5: 0.9268
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7662988966900702, 'ACC_ID': 0.6108324974924775, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 2999: Top1: 0.7640; Top5: 0.9231
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7641950567802271, 'ACC_ID': 0.5938543754175016, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 3999: Top1: 0.7673; Top5: 0.9266
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7674650698602794, 'ACC_ID': 0.5983033932135728, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 4999: Top1: 0.7704; Top5: 0.9277
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7704590818363274, 'ACC_ID': 0.6055888223552894, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 5999: Top1: 0.7682; Top5: 0.9276
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7682602921646746, 'ACC_ID': 0.6049136786188579, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 6999: Top1: 0.7680; Top5: 0.9263
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7680045545118133, 'ACC_ID': 0.6040421292342727, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 7999: Top1: 0.7676; Top5: 0.9262
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7676969092721835, 'ACC_ID': 0.6071784646061814, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 8999: Top1: 0.7661; Top5: 0.9250
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7660805697752059, 'ACC_ID': 0.6058312931226352, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 9999: Top1: 0.7632; Top5: 0.9232
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7632792142713971, 'ACC_ID': 0.6049308478653037, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 10999: Top1: 0.7646; Top5: 0.9233
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7645032632342277, 'ACC_ID': 0.6075054387237129, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 11999: Top1: 0.7653; Top5: 0.9237
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7653010449494112, 'ACC_ID': 0.6065682534416985, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 12999: Top1: 0.7660; Top5: 0.9231
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7660261337432744, 'ACC_ID': 0.605380476556495, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 13999: Top1: 0.7641; Top5: 0.9232
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.764102564102564, 'ACC_ID': 0.6037037037037037, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 14999: Top1: 0.7639; Top5: 0.9242
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.763901791639018, 'ACC_ID': 0.6038487060384871, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 15999: Top1: 0.7629; Top5: 0.9236
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7629444791016844, 'ACC_ID': 0.6038677479725515, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 16999: Top1: 0.7649; Top5: 0.9253
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7646575020561626, 'ACC_ID': 0.6050992832804606, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 17999: Top1: 0.7650; Top5: 0.9249
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7648492907801419, 'ACC_ID': 0.6050531914893617, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 18999: Top1: 0.7638; Top5: 0.9244
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7636172450052576, 'ACC_ID': 0.6055730809674027, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 19999: Top1: 0.7636; Top5: 0.9242
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7635, 'ACC_ID': 0.6066, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}
[       inf 0.38955608 0.33961836 ... 0.22940871 0.22932588 0.16724499]
ImagenetROOD MNIST rosita_loss_txt maxlogit


Final metrics: Top-1 accuracy: 76.3600; Top-5 accuracy: 92.4200
{'Method': 'rosita_loss_txt', 'AUC': 0.900764935, 'FPR95': 0.8122, 'ACC_ALL': 0.7635, 'ACC_ID': 0.6066, 'ACC_OOD': 0.9836, 'ACC_HM': 0.7504109671739405, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}




Namespace(N_m=512, alpha=0.5, batch_size=1, classifier_type='txt', corruption='snow', dataroot='/home/manogna/TTA/PromptAlign/data/ood', dataset='ImagenetROOD', k_n=10, k_p=3, level=5, loss_pl=0, loss_simclr=0, model='maple', model_type='ViT-B/16', n_views=64, ood_detector='maxlogit', out_dir='./logs', pl_thresh=0.6, seed=0, strong_OOD='SVHN', strong_ratio=1, tta_method='rosita_loss', workers=4)


len 10000
dict_values(['goldfish', 'great white shark', 'hammerhead shark', 'stingray', 'hen', 'ostrich', 'goldfinch', 'junco', 'bald eagle', 'vulture', 'smooth newt', 'axolotl', 'tree frog', 'green iguana', 'chameleon', 'Indian cobra', 'scorpion', 'tarantula', 'centipede', 'peafowl', 'lorikeet', 'hummingbird', 'toucan', 'duck', 'goose', 'black swan', 'koala', 'jellyfish', 'snail', 'American lobster', 'hermit crab', 'flamingo', 'great egret', 'pelican', 'king penguin', 'grey whale', 'killer whale', 'sea lion', 'Chihuahua', 'Shih Tzu', 'Afghan Hound', 'Basset Hound', 'Beagle', 'Bloodhound', 'Italian Greyhound', 'Whippet', 'Weimaraner', 'Yorkshire Terrier', 'Boston Terrier', 'Scottish Terrier', 'West Highland White Terrier', 'Golden Retriever', 'Labrador Retriever', 'Cocker Spaniel', 'collie', 'Border Collie', 'Rottweiler', 'German Shepherd Dog', 'Boxer', 'French Bulldog', 'St. Bernard', 'Siberian Husky', 'Dalmatian', 'pug', 'Pomeranian', 'Chow Chow', 'Pembroke Welsh Corgi', 'Toy Poodle', 'Standard Poodle', 'grey wolf', 'hyena', 'red fox', 'tabby cat', 'leopard', 'snow leopard', 'lion', 'tiger', 'cheetah', 'polar bear', 'meerkat', 'ladybug', 'fly', 'bee', 'ant', 'grasshopper', 'cockroach', 'praying mantis', 'dragonfly', 'monarch butterfly', 'starfish', 'cottontail rabbit', 'porcupine', 'fox squirrel', 'beaver', 'guinea pig', 'zebra', 'pig', 'hippopotamus', 'bison', 'gazelle', 'llama', 'skunk', 'badger', 'orangutan', 'gorilla', 'chimpanzee', 'gibbon', 'baboon', 'giant panda', 'eel', 'clownfish', 'pufferfish', 'accordion', 'ambulance', 'assault rifle', 'backpack', 'barn', 'wheelbarrow', 'basketball', 'bathtub', 'lighthouse', 'beer glass', 'binoculars', 'birdhouse', 'bow tie', 'broom', 'bucket', 'cauldron', 'candle', 'cannon', 'canoe', 'carousel', 'castle', 'mobile phone', 'cowboy hat', 'electric guitar', 'fire truck', 'flute', 'gas mask or respirator', 'grand piano', 'guillotine', 'hammer', 'harmonica', 'harp', 'hatchet', 'jeep', 'joystick', 'lab coat', 'lawn mower', 'lipstick', 'mailbox', 'missile', 'mitten', 'parachute', 'pickup truck', 'pirate ship', 'revolver', 'rugby ball', 'sandal', 'saxophone', 'school bus', 'schooner', 'shield', 'soccer ball', 'space shuttle', 'spider web', 'steam locomotive', 'scarf', 'submarine', 'tank', 'tennis ball', 'tractor', 'trombone', 'vase', 'violin', 'military aircraft', 'wine bottle', 'ice cream', 'bagel', 'pretzel', 'cheeseburger', 'hot dog', 'cabbage', 'broccoli', 'cucumber', 'bell pepper', 'mushroom', 'Granny Smith apple', 'strawberry', 'lemon', 'pineapple', 'banana', 'pomegranate', 'pizza', 'burrito', 'espresso', 'volcano', 'baseball player', 'scuba diver', 'acorn'])
len 10000
Using downloaded and verified file: /home/manogna/TTA/PromptAlign/data/ood/train_32x32.mat
10000 10000 20000
MaPLe design: Multi-modal Prompt Learning
Initial context: "a photo of a"
Number of MaPLe context words (tokens): 2

Step 999: Top1: 0.7675; Top5: 0.9115
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7674897119341564, 'ACC_ID': 0.6234567901234568, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 1999: Top1: 0.7663; Top5: 0.9268
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7662988966900702, 'ACC_ID': 0.6118355065195586, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 2999: Top1: 0.7640; Top5: 0.9231
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7641950567802271, 'ACC_ID': 0.5998663994655978, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 3999: Top1: 0.7673; Top5: 0.9266
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7674650698602794, 'ACC_ID': 0.6027944111776448, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 4999: Top1: 0.7704; Top5: 0.9277
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7704590818363274, 'ACC_ID': 0.6091816367265469, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 5999: Top1: 0.7682; Top5: 0.9276
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7682602921646746, 'ACC_ID': 0.6079017264276229, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 6999: Top1: 0.7680; Top5: 0.9263
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7680045545118133, 'ACC_ID': 0.6068886991175634, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 7999: Top1: 0.7676; Top5: 0.9262
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7676969092721835, 'ACC_ID': 0.6096709870388833, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 8999: Top1: 0.7661; Top5: 0.9250
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7660805697752059, 'ACC_ID': 0.6080569775205876, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 9999: Top1: 0.7632; Top5: 0.9232
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7632792142713971, 'ACC_ID': 0.6075365804770495, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 10999: Top1: 0.7646; Top5: 0.9233
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7645032632342277, 'ACC_ID': 0.6098622189992748, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 11999: Top1: 0.7653; Top5: 0.9237
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7653010449494112, 'ACC_ID': 0.6093879582020235, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 12999: Top1: 0.7660; Top5: 0.9231
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7660261337432744, 'ACC_ID': 0.6102997694081476, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 13999: Top1: 0.7641; Top5: 0.9232
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.764102564102564, 'ACC_ID': 0.6086894586894587, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 14999: Top1: 0.7639; Top5: 0.9242
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.763901791639018, 'ACC_ID': 0.608493696084937, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 15999: Top1: 0.7629; Top5: 0.9236
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7629444791016844, 'ACC_ID': 0.6082345601996257, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 16999: Top1: 0.7649; Top5: 0.9253
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7646575020561626, 'ACC_ID': 0.6092116085066385, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 17999: Top1: 0.7650; Top5: 0.9249
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7648492907801419, 'ACC_ID': 0.6089317375886525, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 18999: Top1: 0.7638; Top5: 0.9244
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7636172450052576, 'ACC_ID': 0.6092534174553103, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}

Step 19999: Top1: 0.7636; Top5: 0.9242
{'Method': 'rosita_loss_txt', 'AUC': 0, 'FPR95': 0, 'ACC_ALL': 0.7635, 'ACC_ID': 0.6101, 'ACC_OOD': 0, 'ACC_HM': 0, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}
[       inf 0.38955608 0.33961836 ... 0.2192432  0.21895342 0.16724499]
ImagenetROOD SVHN rosita_loss_txt maxlogit


Final metrics: Top-1 accuracy: 76.3600; Top-5 accuracy: 92.4200
{'Method': 'rosita_loss_txt', 'AUC': 0.9261948899999999, 'FPR95': 0.663, 'ACC_ALL': 0.7635, 'ACC_ID': 0.6101, 'ACC_OOD': 0.9925, 'ACC_HM': 0.755677336827655, 'kp': 3, 'kn': 10, 'alpha': 0.5, 'loss_pl': 0, 'loss_simclr': 0, 'OOD Detector': 'maxlogit'}




1 0
